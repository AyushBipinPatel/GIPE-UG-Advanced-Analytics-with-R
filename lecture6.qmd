---
title: "Linear Model Selection and Regularization"
subtitle: "Advance Analytics with R (UG 21-24)"
author: "Ayush Patel"
format: 
  revealjs:
    embed-resources: true
    slide-number: c/t
    width: 1400
    theme: [serif, theme.scss]
---
```{r echo=FALSE,message=FALSE,warning=FALSE}

library(tidyverse)
library(MASS)
library(ISLR)
library(ISLR2)
library(patchwork)
library(glmnet)

```


## Before we start

::: columns
::: {.column width="70%"}

Please load the following packages

```{r}
#| eval: false
#| echo: true

library(tidyverse)
library(MASS)
library(ISLR)
library(ISLR2)
library(nnet)### get this if you don't
library(e1071) ## get this if you don't
library(modeldata)## get this if you don't

```

<br> <br>

Access lecture slide from [bit.ly/aar-ug](http://bit.ly/aar-ug)
:::

::: {.column width="30%"}
```{=html}
<figure>
<img src="https://images.metmuseum.org/CRDImages/aa/original/DT5334.jpg" alt="Warrior's armor(gusoku)" >
<figcaption style="font-size:10px;">Source: <a herf = "https://www.metmuseum.org/art/collection/search/24975?searchField=All&amp;sortBy=Relevance&amp;high=on&amp;ao=on&amp;showOnly=openAccess&amp;ft=start&amp;offset=0&amp;rpp=40&amp;pos=7">Armor (Gusoku)</a></figcaption>
</figure>
```
:::
:::

## Hello

::: columns
::: {.column width="70%"}
I am [Ayush]{.fragment fragment-index="1" style="font-size:45px"}.

[I am a researcher working at the intersection of data, law, development and economics.]{.fragment fragment-index="2" style="font-size:25px"}

[I teach Data Science using R at Gokhale Institute of Politics and Economics]{.fragment fragment-index="3" style="font-size:25px"}

[I am a [RStudio (Posit) certified tidyverse Instructor.](https://education.rstudio.com/trainers/people/patel+ayush/)]{.fragment fragment-index="4" style="font-size:25px"}

[I am a Researcher at [Oxford Poverty and Human development Initiative (OPHI)](https://ophi.org.uk/), at the University of Oxford.]{.fragment fragment-index="5" style="font-size:25px"}
:::

::: {.column width="30%"}
**Reach me**

{{< fa solid envelope >}} [ayush.ap58\@gmail.com]{style="font-size:25px"}

{{< fa solid envelope >}} [ayush.patel\@gipe.ac.in]{style="font-size:25px"}
:::
:::

## Why are we still talkig about linear models?

> When there are many fancy things to try out!!

  + **Inference Advantage**
  + **Real World Problems Advantage**
  + **Competitive** compared to non-linear models. 
  
> Therefore, we discuss linear models beyond least squares estimate.

## What do we gain?

>**Prediction Accuracy**:

  + If Y and X are approximately linear, least square approach has low bias.
  + For $n>>p$, least square has low variance as well.
  + But, if $n>>p$ is not held, least square has high variance and poor prediction ability on future observations.
  + And if $p>n$, then there are infinitely many solutions to least square method.
  
## What do we gain?

> **Model Interpretability**

  + too many predictors make a complex model.
  + Sometimes, some predictors may not even have a real relation with the response.
  + We reduce coeffs of Irrelevant variables to 0.
  + We discuss approaches of feature selection.
  
## Subset Selection{.center}

> *"This approach involves identifying a subset of the p predictors that we believe to be related to the response. We then fit a model using least squares on the reduced set of variables."*

  + Best Subset
  + Stepwise selection
  
## Subset Selection - *Best Subset*

A least square model is fit for all possible combinations of p predictors.

So, if there are 3 predictors ($p_1,p_2,p_3$), we fit the following models:

model 1 $y = \beta_a + \beta_1*p_1$ <br>
model 2 $y = \beta_b + \beta_2*p_2$ <br>
model 3 $y = \beta_c + \beta_3*p_3$ <br>
.<br>
.<br>
model 7 $y = \beta_0 + \beta_e*p_1 + \beta_f*p_2 + \beta_g*p_3$

> Select the best from these

## Subset Selection - *Best Subset*

  + A null model is defined with no predictors. Name it $M_0$
  
  + For each $k$, where $k=1,2,3..p$, select the best model from the all $(_k^p)$ combinations. Use RSS or $R^2$. Call it $M_k$
  
  + Select a single best model from $M_0, M_1,.....,M_p$. Use prediction error on a validation set,$C_p$, AIC, BIC, adjusted $R^2$ or use the cross validation method. 
  
## Subset Selection - *Best Subset*{.center}

> Issues:

  + Computational limitations.
  + *" The larger the search space, the higher the chance of finding models that look good on the training data, even though  they might not have any predictive power on future data. "*
  
## Subset Selection - *Forward Stepwise Selection*

  + Start with Null model. $M_0$
  + For all $p-k$ models, choose the best using $R^2$ or RSS.       
  + Select a single best model from $M_0, M_1,.....,M_p$. Use prediction error on a validation set,$C_p$, AIC, BIC, adjusted $R^2$ or use the cross validation method.
  
  
## Subset Selection - *Forward Stepwise Selection*

> Issues:

  + *"Though forward stepwise tends to do well in practice, it is not guaranteed to find the best possible model out of all 2p models containing subsets of the p predictors."*

## Subset Selection - *Backward Stepwise Selection*

  + Start with full model. $M_p$
  + Consider all k models that contain all but one of the predictors in $M_k$, for a total of k − 1 predictors. Choose the best among these k models, and call it Mk−1. Here
best is defined as having smallest RSS or highest $R^2$       
  + Select a single best model from $M_0, M_1,.....,M_p$. Use prediction error on a validation set,$C_p$, AIC, BIC, adjusted $R^2$ or use the cross validation method.
  
## Choose wisely

We generate several models using best subset selection, forward stepwise and backward stepwise.

> We must choose carefully which models to pick. We ideally want a model that will have the lowest test error rate.

  + Estimate test error rate by adjusting training error rate for bias due to overfitting.
  + Cross validation.
  
## The four horsemen

> $C_p$, AIC,BIC, Adjusted $R^2$

Recall that $MSE = RSS/n$. Also, since we use least squares approach to choose coeffs in a manner where training RSS is minimized, we end up getting a training MSE is an underestimate of test MSE.

**That is the reason $R^2$ and training RSS are not suitable for selecting from many models.**

> Therefore we learn about $C_p$, Akaike Information criterion (AIC), Bayesian Information Criterion (BIC) and Adjusted $R^2$

## The four horsemen - $C_p$

Say there is a least square model with $d$ predictors.

The estimate of test error rate is given by:

$$C_p = \frac{1}{n}(RSS + 2d\hat\sigma^2)$$


$\hat\sigma^2$ is the estimate of variance of $\epsilon$, estimated using a full model.

## The four horsemen - AIC

AIC is defined for a range of maximum likelihood models. 


$$AIC = 2d - 2ln(L)$$


$$AIC = \frac{1}{n}(RSS + 2d\hat\sigma^2)$$

## The four horsemen - BIC{.center}

BIC, for a least square model with d predictors:

$$BIC = \frac{1}{n}(RSS + log(n)d\hat\sigma^2   )$$

## The four horsemen - Adjusted $R^2${.center}

$$Adjusted\hspace{1mm} R^2 =   \frac{RSS(n-d-1)}{TSS(n-1)}$$


## Cross Validation - an alternative to the horsemen {.center}

  + Instead of *adjusting* we can directly estimate test error rate.
  + Makes fewer assumptions about underlying model.
  
  
## Exercise - best subset

See 6.5.1 in ISLR 

Apply best subset approach for the Auto data in ISLR2 package.

Use mpg as response.

What is the best model? Feel free to use ggplot for charts and broom to collect stats from model object.

## Exercise  - Validation set

See 6.5.1 in ISLR

Apply validation set approach on Auto data in ISLR2 package.

Use mpg as response.

Which is the best model?

## Shrinkage Methods{.center}

In subsetset selection methods we are working with least squares. 

Alternatively, we try to reduce the coefficients in a full model to zero. This is referred to shrinkage, constraining or regularization. 

This reduces variance of coefficients, leading to a better bit.

> Ridge and Lasso are two techniques that allow us to do this.

## Ridge Regression

In least square method we minimize RSS to estimate coefficients.

In Ridge we minimize:

$$RSS + \lambda \sum_{j=1}^p\beta_j^2$$

$\lambda >= 0$ is the tuning parameter.

> Ridge Regression produces mroe than 1 set of coefficients.
<br>
> Ridge Regression is not scale equivariant.

## Ridge Regression{.center}

Since it is not scale equivariant, apply only after standardizing the predictors.

$$\tilde x = \frac{x_{ij}}{\sqrt{\frac{1}{n}\sum_{i=1}^j(x_{ij} - \bar{x_{ij}})^2}}$$

## Apply Ridge{.scrollable}



```{r}
#| echo: true

## Remove all NA

Hitters |>
  na.omit() -> hit_no_miss

## Model Matrix

x <- model.matrix(Salary ~., hit_no_miss)[,-1]

y <- hit_no_miss$Salary

## ridge

10^seq(10, -2, length = 100) -> lambdas

glmnet(x, y, alpha = 0, 
       lambda = lambdas) -> mod_ridge

## Model Object

mod_ridge|>
  broom::tidy()|>
  knitr::kable()%>%
  kableExtra::kable_styling()%>%
  kableExtra::scroll_box(width = "100%", height = "400px")
  

```
## Exercise Ridge Regression

Use the birthwt data. Your response is variable bwt.

Apply a ridge regression.

Then create training and testing set(split your preference).

Create two charts:

  + Chart1 : X-axis lambda value, Y-axis MSE. Plot train and test MSE for each lambda value.
  + Chart2: X-axis lambda value, Y-axis standardized coeffs. Plot coeff estimates for all predictors.

## Ridge Issue{.scrollable}


> We have to deal with a full model. Interpretability becomes difficult, though not an isuue with prediction accuracy.

:::{.panel-tabset}

#### Code

```{r}
#| echo: true
#| fig-width: 12
#| fig-height: 8

mod_ridge|>
  broom::tidy()|>
  filter(term != "(Intercept)")|>
  ggplot(aes(lambda,estimate,
             colour = term))+
  geom_line()+
  guides(colour = guide_legend(nrow = 2))+
  scale_x_log10(
    breaks = scales::log_breaks(n = 10)
    )+
  labs(
    x = "log10 lambda"
  )+
  theme_minimal()+
  theme(
    legend.position = "top",
    legend.direction = "horizontal"
  ) -> p_coeff_lambda

```

#### Plot

```{r}
p_coeff_lambda
```




:::

## The Lasso

An alternative to ridge that overcomes the full model advantage.

$$RSS + \lambda \sum_{j=1}^p|\beta_j|$$

Notice the difference in Lasso and Ridge?

Lasso uses $\ell_2$ and Ridge uses $\ell_2$.

The $\ell_1$  norm of coeff vector is $||\beta||_1 = \sum_{j=1}^p|\beta_j|$

The $\ell_1$  norm of coeff vector is $||\beta||_2 = \sum_{j=1}^p(\beta_j)^2$

## Applying Lasso{.scrollable}


:::{.panel-tabset}

#### Code

```{r}
#| echo: true

glmnet(x, y, alpha = 1, 
       lambda = lambdas) -> mod_lasso

```

#### comparison

::::{.columns}

:::{.column}

### Ridge

```{r}
p_coeff_lambda+
  labs(title = "Ridge")
```

:::

:::{.column}

### Lasso

```{r}
mod_lasso|>
  broom::tidy()|>
  filter(term != "(Intercept)")|>
  ggplot(aes(lambda,estimate,
             colour = term))+
  geom_line()+
  guides(colour = guide_legend(nrow = 2))+
  scale_x_log10(
    breaks = scales::log_breaks(n = 10)
    )+
  labs(
    x = "log10 lambda",
    title = "Lasso"
  )+
  theme_minimal()+
  theme(
    legend.position = "top",
    legend.direction = "horizontal"
  )
```
:::

::::

:::
