---
title: "Multiple Testing"
subtitle: "Advance Analytics with R (UG 21-24)"
author: "Ayush Patel"
format: 
  revealjs:
    embed-resources: true
    slide-number: c/t
    width: 1400
    theme: [serif, theme.scss]
---
```{r echo=FALSE,message=FALSE,warning=FALSE}

library(tidyverse)
library(MASS)
library(ISLR)
library(ISLR2)
library(patchwork)
library(glmnet)

```


## Before we start

::: columns
::: {.column width="70%"}

Please load the following packages

```{r}
#| eval: false
#| echo: true

library(tidyverse)
library(MASS)
library(ISLR)
library(ISLR2)
library(infer)### get this if you don't

```

<br> <br>

Access lecture slide from [bit.ly/aar-ug](http://bit.ly/aar-ug)
:::

::: {.column width="30%"}
```{=html}
<figure>
<img src="https://images.metmuseum.org/CRDImages/aa/original/DT5334.jpg" alt="Warrior's armor(gusoku)" >
<figcaption style="font-size:10px;">Source: <a herf = "https://www.metmuseum.org/art/collection/search/24975?searchField=All&amp;sortBy=Relevance&amp;high=on&amp;ao=on&amp;showOnly=openAccess&amp;ft=start&amp;offset=0&amp;rpp=40&amp;pos=7">Armor (Gusoku)</a></figcaption>
</figure>
```
:::
:::

## Hello

::: columns
::: {.column width="70%"}
I am [Ayush]{.fragment fragment-index="1" style="font-size:45px"}.

[I am a researcher working at the intersection of data, law, development and economics.]{.fragment fragment-index="2" style="font-size:25px"}

[I teach Data Science using R at Gokhale Institute of Politics and Economics]{.fragment fragment-index="3" style="font-size:25px"}

[I am a [RStudio (Posit) certified tidyverse Instructor.](https://education.rstudio.com/trainers/people/patel+ayush/)]{.fragment fragment-index="4" style="font-size:25px"}

[I am a Researcher at [Oxford Poverty and Human development Initiative (OPHI)](https://ophi.org.uk/), at the University of Oxford.]{.fragment fragment-index="5" style="font-size:25px"}
:::

::: {.column width="30%"}
**Reach me**

{{< fa solid envelope >}} [ayush.ap58\@gmail.com]{style="font-size:25px"}

{{< fa solid envelope >}} [ayush.patel\@gipe.ac.in]{style="font-size:25px"}
:::
:::

## Motivation for Tests for Significance

  + Helps us answer - *Is it just chance?*
  + Understand and quantify uncertainty and variability.
  
> Helps us make and verify claims about a population using sample estimates.

> Helps us make and verify causal claims.

## The numbered tickets example{.center}

refer: Statistics by David Freedman

## Example{.center}

> Write a simulation that will implement the previous example.

## The sex discrimination case study{.center}

refer: Intro to Modern Statics 

## A little about simulation and {infer} {.scrollable}

::::{.columns}

:::{.column}

### Base

```{r}
#| echo: true

get_diffs <- function(...){
  
  decisions <- ifelse(
  openintro::sex_discrimination$decision == "promoted",
  1,0
)

sample(decisions,
       size = 48,
       replace = F) -> shuffled_decision

mean(shuffled_decision[1:24]) - mean(shuffled_decision[24:48])
  
}

map_dbl(c(1:100), 
        get_diffs)

```


:::


:::{.column}

### infer

```{r}
#| echo: true

openintro::sex_discrimination|>
  infer::specify(decision ~ sex,
                 success = "promoted")|>
  infer::hypothesise(null = "independence")|>
  infer::generate(reps = 100,
                  type = "permute")|>
  infer::calculate(stat = "diff in props",
                   order = c("male","female"))
```

:::


::::

## Both work fine{.scrollable}
 *but what is convenient*
 
```{r}
#| echo: true

tibble(
  base_diffs = map_dbl(c(1:1000), 
        get_diffs),
  infer_diffs = openintro::sex_discrimination|>
  infer::specify(decision ~ sex,
                 success = "promoted")|>
  infer::hypothesise(null = "independence")|>
  infer::generate(reps = 1000,
                  type = "permute")|>
  infer::calculate(stat = "diff in props",
                   order = c("male","female"))|>
    pull(stat)
) -> differences_in_props

differences_in_props

```

## Both work fine{.scrollable}

```{r}
differences_in_props|>
  ggplot()+
  geom_density(aes(base_diffs),
               colour = "steelblue")+
  geom_density(aes(infer_diffs),
               colour = "hotpink")+
  theme_minimal()+
  labs(
    title = "Both ways generate similar results",
    x = "Differences in proportoions"
  ) -> plt

plt
```

## Get p-values

::::{.columns}

:::{.column}

### Base

```{r}
#| echo: true

map_dbl(
  c(1:1000),
  get_diffs
) >= 0.292 -> greater_equal_obs_stat

sum(greater_equal_obs_stat)/1000

```


:::


:::{.column}

### infer

```{r}
#| echo: true


  openintro::sex_discrimination|>
  infer::specify(decision ~ sex,
                 success = "promoted")|>
  infer::hypothesise(null = "independence")|>
  infer::generate(reps = 1000,
                  type = "permute")|>
  infer::calculate(stat = "diff in props",
                   order = c("male","female"))|>
  infer::get_p_value(obs_stat = 0.292,
                     direction = "right")
    

```


:::


::::

## Exercise

Use both methods for the sex discrimination study, iterate several times. Show that both methods generate similar p-values.

## Testing Framework{.center}

  + Define Null and Alternative Hypothesis
  + Construct Test Statistic
  + Compute p-value
  + Decide to reject the Null or fail to reject
  
## Type I and Type II Errors{.center}

   + Type 1 Error: $H_0$ is actually true but we erroneously reject it.
   + Type 2 Error: $H_0$ is actually not true and we fail to reject it.
   + Power of Hypothesis test: probability of not making Type 2 error when $H_a$ actually holds.
   
## The Multiple Testing problem{.center}

> Discuss the coin flip example from ISLR

:::{.callout-note}

If we test hundreds of Null Hypothesis, and reject all with p-value 0.01, *How many type 1 errors should be expected.* 

:::


## The Family-Wise Error Rate

> The probablity of making at least one Type I error when testing m hypothesis.

Decision            | $H_o$ is True | $H_o$ is False | Total
--------------------|---------------|----------------|-------
Reject $H_o$        |       V       |        S       |  R  
Do Not Reject $H_o$ |       U       |        W       |  m - R
Total               |      $m_o$    |        m-$m_o$ |  m


$FWER = Pr(V>=1)$

## The Family-Wise Error Rate

$$FWER(\alpha) = 1 - Pr(V = 0)$$

$$FWER(\alpha) =  1 - \prod_{j=1}^m (1-\alpha) = 1 - (1-\alpha)^m$$

## The Family-Wise Error Rate

```{r}
#| echo: false
#| fig-width: 9


tibble::tibble(
  num_h = c(1:500),
  a_001 = 1 - (1-0.001)^num_h,
  a_01 = 1 - (1-0.01)^num_h,
  a_05 = 1 - (1-0.05)^num_h
)|>
  ggplot()+
  geom_line(aes(num_h, a_05),
            colour = "#253485")+
  geom_line(aes(num_h, a_01),
            colour = "#299827")+
  geom_line(aes(num_h, a_001),
            colour = "#288885")+
  geom_hline(aes(yintercept = 0.05),
             linetype = 2)+
  scale_x_log10(breaks = c(1,2,5,10,20,50,100,200,500))+
  labs(
    y = "FWER at a given alpha",
    x = "Number of Hypothesis"
  )+
  theme_minimal()

```
## The Fund data{.scrollable}

```{r}
#| echo: false

Fund|>
  str()

```

## Bonferroni Correction

$$ FWER =  Pr(making at least 1 type 1 error)$$

Assume that $A_j$ is an event where we make a type1 error.

$FWER = Pr(\bigcup_{j=1}^m A_j)$

$FWER <= \sum_{j=1}^m Pr(A_j)$

$FWER(\alpha/m) <= m * \frac{\alpha}{m}$

## Exercise

On the Fund data run independent t test ($\alpha = 0.05$)for each fund manager to see if average excess returns are nonzero. Then run again with Bonferroni correction and see how many are still non-zero.

## Bonferroni - to remember

  + Commonly used
  + Save us from rejecting too many null hypothesis
  + The cost: We end up making a few Type II errors
  + Easy to understand
  + Works regardless whether m hypothesis are independent
  + True FWER is usually lowers that the Bonferroni or target FWER
  
## Holm's Step-Down Prodecure

Procedure:

  + Choose $\alpha$, at which to control FWER
  + Compute p-values, $p_1,p_2,p_3,...,p_m$
  + Sort all p-values, $p_{(1)} \le p_{(2)} \le p_{(3)} \le...\le p_{(m)}$
  + Define $$L = min{j : p_{(j)} > \frac{\alpha}{m+1-j}}$$
  + Reject all $H_0$ where $p_j<p_{(L)}$
  
## Funds data testing{.scrollable}

```{r}
#| echo: true

## run t-test for all fund managers at 0.05

Fund|>
  summarise(
    across(
      everything(),
      .fns = ~ t.test(.x, mu = 0)$p.value
    )
  )|>
  pivot_longer(
    everything(),
    names_to = "Manager",
    values_to = "Independent_t.test_pval"
  ) -> all_test_pvalues

head(all_test_pvalues)

```

```{r}
#| echo: true

# mark where null is rejected using bonferroni 

all_test_pvalues|>
  mutate(
    reject_null_for_bonferroni = Independent_t.test_pval <= (0.05/2000)
  ) -> all_test_pvalues

head(all_test_pvalues)

```

```{r}
#| echo: true

## Execute the Holm's Step-Down procedure

all_test_pvalues |>
  arrange(Independent_t.test_pval) |> # step 2 ascending
  mutate(
    index = c(1:2000),
    is_L_val = (0.05/(2000+1-index)),
    is_L = Independent_t.test_pval > is_L_val
  )|> 
  filter(is_L == T & is_L_val == min(is_L_val))|>
  pull(Independent_t.test_pval) -> holms_L


## reject null hypothesis where pvalues are less than L

all_test_pvalues|>
  mutate(
    reject_null_for_holms = Independent_t.test_pval < holms_L
  )|>
  
  ### compare results
  
  summarise(
    rejected_nulls_vanilla = sum(Independent_t.test_pval<=0.05),
    rejected_nulls_bonferroni = sum(reject_null_for_bonferroni),
    rejected_nulls_holms = sum(reject_null_for_holms)
  )|>
  gt::gt()



```


## False Discovery Rate

**Preventing all false positives can cost of power of the test.**

So, we try and ensure that $\frac{V}{R}, R = V + S (sum\hspace{1mm}of\hspace{1mm}all\hspace{1mm}positives),$ is minimum. This ratio is the False Discovery Proportion.

False Discovery Rate is the expectation of FDP. We try and control this.

## Benjamini-Hochberg Procedure

  + Choose $q$, at which to control FDR
  + Compute p-values, $p_1,p_2,p_3,...,p_m$
  + Sort all p-values, $p_{(1)} \le p_{(2)} \le p_{(3)} \le...\le p_{(m)}$
  + Define $$L = max{j : p_{(j)} < \frac{qj}{m}}$$
  + Reject all $H_0$ where $p_j \le p_{(L)}$
  
## What if the theoretical Null distribution is not known?{.center}